{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\n### Flower Recognition\nI love to hike. One of the things I love most about hiking is gazing upon the many different varieties of flowers seen in nature, however, I have always been bad at recognizing different types of flowers (even some of the more easily recognizable ones). For this reason, I thought \"why not build a neural network that can classify images of flowers?\" By building an neural network that can classify the image of any flower that I give it, I hope that I will be able to start to improving my own flower recognition capabilities as well! In this notebook I use the [Flowers Recognition](https://www.kaggle.com/alxmamaev/flowers-recognition) data set which is comprised of flower images from Flickr, Google images, and Yandex images to train a neural network to classify images of 5 different types of flowers. While this is a small number of flowers to recognize given the many many different species of flowers that actually exist in nature, I hope to eventually add many more images of different types of flowers to the training set to increase the number of flower species it can classify. I will use Tensorflow to build a Convolutional Neural Network to approach this problem.\n\n### Import all required packages","metadata":{}},{"cell_type":"code","source":"# Importing all packages I will use throughout this notebook\nimport numpy as np\nimport pandas as pd \nimport os\nimport PIL\nimport matplotlib.pyplot as plt\nfrom IPython import display\nimport random\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.python.framework import ops\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (20, 15)\npath = '../input/flowers-recognition/flowers/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-21T22:59:33.481581Z","iopub.execute_input":"2022-01-21T22:59:33.482009Z","iopub.status.idle":"2022-01-21T22:59:35.869592Z","shell.execute_reply.started":"2022-01-21T22:59:33.481894Z","shell.execute_reply":"2022-01-21T22:59:35.868706Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the image data\n\nLet's explore the data set. The data is in 1 of 5 folders: 'daisy', 'dandelion', 'rose', 'sunflower', and 'tulip'. Each folder has roughly ~800-1000 images. Let's have a look at 20 randomly selected images from the full data set.","metadata":{}},{"cell_type":"code","source":"## Define function to plot 20 random images from list_of_images\ndef show_random_images(path, labels):\n    for i in range(20):\n        label_idx = random.randint(0, len(labels)-1) # Select folder at random to choose from\n        im_path = path + labels[label_idx] + '/'\n        image_idx = random.randint(0, len([name for name in os.listdir(im_path)])-1) # Select image at random from folder\n        image_names = [name for name in os.listdir(im_path) ]\n        plt.subplot(4,5,i+1).set_title(labels[label_idx])\n        plt.imshow(PIL.Image.open(im_path + image_names[image_idx]))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:35.871759Z","iopub.execute_input":"2022-01-21T22:59:35.872073Z","iopub.status.idle":"2022-01-21T22:59:35.879761Z","shell.execute_reply.started":"2022-01-21T22:59:35.872035Z","shell.execute_reply":"2022-01-21T22:59:35.878806Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"path = '../input/flowers-recognition/flowers/'\nflowers = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n\nshow_random_images(path, flowers)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:35.881085Z","iopub.execute_input":"2022-01-21T22:59:35.881635Z","iopub.status.idle":"2022-01-21T22:59:39.058869Z","shell.execute_reply.started":"2022-01-21T22:59:35.881580Z","shell.execute_reply":"2022-01-21T22:59:39.058092Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"The images are different sizes, so we will need to resize all of them before feeding them to a neural network. Let's try this first with PIL.\n\n## Image Resizing\nFirst we will need to open the images with PIL and then resize them. Let's start by resizing to 64x64 images.","metadata":{}},{"cell_type":"code","source":"## Compute total number of images\ntotal_images = 0\nfor flower in flowers:\n    total_images += len([name for name in os.listdir(path + flower + '/')])\n\n\n## Create an array of resized images\nimages = np.empty((total_images, 64, 64, 3),dtype=np.int32)\nlabels = np.empty(total_images,dtype=np.int32)\nn = 0\nfor i in range(len(flowers)):\n    im_path = path + flowers[i] + '/'\n    for name in os.listdir(im_path):\n        labels[n] = i\n        images[n,:,:,:] = np.array(PIL.Image.open(im_path + name).resize((64,64), PIL.Image.BICUBIC))\n        n += 1","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:39.060545Z","iopub.execute_input":"2022-01-21T22:59:39.060818Z","iopub.status.idle":"2022-01-21T22:59:55.489745Z","shell.execute_reply.started":"2022-01-21T22:59:39.060785Z","shell.execute_reply":"2022-01-21T22:59:55.488848Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"The images are now stored in a $(m \\times 64 \\times 64 \\times 3)$ array, where $m$ is the number of training examples. Let's see how the resized images look.","metadata":{}},{"cell_type":"code","source":"## Plot 20 random images that have been resized in the aprevious step\nrandomlist = random.sample(range(0, images.shape[0]), 20)\ni = 1\nfor r in randomlist:\n    plt.subplot(4,5,i).set_title('{}'.format(flowers[labels[r]]))\n    plt.imshow(images[r,:,:,:])\n    i += 1","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:55.492696Z","iopub.execute_input":"2022-01-21T22:59:55.492969Z","iopub.status.idle":"2022-01-21T22:59:58.815027Z","shell.execute_reply.started":"2022-01-21T22:59:55.492939Z","shell.execute_reply":"2022-01-21T22:59:58.814083Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"These look pretty decent! It's time to prepare the data by flattening the image arrays and splitting the data into testing and training data.\n\n### Data preparation and Train/Test Split\n\nFirst thing we will want to do is one-hot encode the target values (i.e., labels).","metadata":{}},{"cell_type":"code","source":"## Define function that will one-hot encode the target values\ndef one_hot_encode(target):\n    n_values = np.max(target) + 1\n    one_hot = np.eye(n_values)[target]\n    return(one_hot)\n\ny = one_hot_encode(labels) # one-hot encode target values\nX = images / np.max(images) # normalize input images\n\nprint(\"X shape:\", X.shape)\nprint(\"y shape:\", y.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:58.816246Z","iopub.execute_input":"2022-01-21T22:59:58.816490Z","iopub.status.idle":"2022-01-21T22:59:59.019508Z","shell.execute_reply.started":"2022-01-21T22:59:58.816462Z","shell.execute_reply":"2022-01-21T22:59:59.018340Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Looks like we have 4,317 images to work with. It is time to perform a train/test split on the data. For now, I will try an 90/10 train/test split so that I will end up 3,885 images to train on and around 430 images to test on.","metadata":{}},{"cell_type":"code","source":"## Split X and y into training and test features + target.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n\n# Quick sanity check to make sure we have the desired array shapes\nprint(\"X training shape:\", X_train.shape)\nprint(\"y training shape:\", y_train.shape)\nprint(\"X testing shape:\", X_test.shape)\nprint(\"y testing shape:\", y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:59.020948Z","iopub.execute_input":"2022-01-21T22:59:59.021235Z","iopub.status.idle":"2022-01-21T22:59:59.157701Z","shell.execute_reply.started":"2022-01-21T22:59:59.021203Z","shell.execute_reply":"2022-01-21T22:59:59.156549Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Build the model\n\nTime to build the model! In the following block of code I add all the layers to the keras.Sequential(\\[\\]) model. First I will perform data augmentation. Then, the first hidden layer will perform a 2D convolution on the input data followed by a 2D max pooling. This process is repeated once more and then we add two dense layers with 512 units follwed by the output layer. I use dropout regularization to reduce overfitting.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.Input(shape=(X.shape[1],X.shape[2],X.shape[3])),\n    RandomFlip('horizontal'), # data augmentation\n    RandomRotation(0.2),\n    tfl.Conv2D(8, 4, strides=1, padding='same'),\n    tfl.ReLU(),\n    tfl.MaxPool2D(pool_size=8, strides=8, padding='same'),\n    tfl.Conv2D(16, 2, strides=1, padding='same'),\n    tfl.ReLU(),\n    tfl.MaxPool2D(pool_size=4,strides=4,padding='same'),\n    tfl.Flatten(),\n    tfl.Dense(512),\n    tfl.Dropout(0.2),\n    tfl.ReLU(),\n    tfl.Dense(512),\n    tfl.Dropout(0.2),\n    tfl.ReLU(),\n    tfl.Dense(units=len(flowers), activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:59.159534Z","iopub.execute_input":"2022-01-21T22:59:59.159893Z","iopub.status.idle":"2022-01-21T22:59:59.358501Z","shell.execute_reply.started":"2022-01-21T22:59:59.159848Z","shell.execute_reply":"2022-01-21T22:59:59.357537Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## Define the optimizer, loss function, metric score and compile\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# View summary of model and trainable parameters\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:59.359569Z","iopub.execute_input":"2022-01-21T22:59:59.359789Z","iopub.status.idle":"2022-01-21T22:59:59.385467Z","shell.execute_reply.started":"2022-01-21T22:59:59.359763Z","shell.execute_reply":"2022-01-21T22:59:59.384495Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Let's fit the model!","metadata":{}},{"cell_type":"code","source":"## Define train and test data sets with batch size = 64\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64)\ntest_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64)\n\n## Fit the model with 100 epochs\nhistory = model.fit(train_dataset, epochs=100, validation_data=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T22:59:59.386784Z","iopub.execute_input":"2022-01-21T22:59:59.387049Z","iopub.status.idle":"2022-01-21T23:04:04.819169Z","shell.execute_reply.started":"2022-01-21T22:59:59.387016Z","shell.execute_reply":"2022-01-21T23:04:04.818163Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_loss_acc = pd.DataFrame(history.history)\ndf_loss= df_loss_acc[['loss','val_loss']]\ndf_loss.rename(columns={'loss':'train','val_loss':'validation'},inplace=True)\ndf_acc= df_loss_acc[['accuracy','val_accuracy']]\ndf_acc.rename(columns={'accuracy':'train','val_accuracy':'validation'},inplace=True)\ndf_loss.plot(title='Model loss',figsize=(12,8)).set(xlabel='Epoch',ylabel='Loss')\ndf_acc.plot(title='Model Accuracy',figsize=(12,8)).set(xlabel='Epoch',ylabel='Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:04:04.820724Z","iopub.execute_input":"2022-01-21T23:04:04.821717Z","iopub.status.idle":"2022-01-21T23:04:05.364368Z","shell.execute_reply.started":"2022-01-21T23:04:04.821682Z","shell.execute_reply":"2022-01-21T23:04:05.363330Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Not too bad. After running this several times the training accuracy always ends up at around 75-80% while the test accuracy typically ends up at around ~70%. Let's see if we can improve this with transfer learning.\n\n# Transfer Learning\n\nLet's use the [MobileNetV2](https://keras.io/api/applications/mobilenet/) model for this approach.\nFirst I will start by defining a function that augments image data which we will call within the model.","metadata":{}},{"cell_type":"code","source":"def data_augmenter():\n    '''\n    Create a Sequential model composed of 2 layers\n    Returns:\n        tf.keras.Sequential\n    '''\n    data_augmentation = tf.keras.Sequential([])\n    data_augmentation.add(RandomFlip('horizontal'))\n    data_augmentation.add(RandomRotation(0.2))    \n    return data_augmentation","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:04:05.365932Z","iopub.execute_input":"2022-01-21T23:04:05.366305Z","iopub.status.idle":"2022-01-21T23:04:05.372111Z","shell.execute_reply.started":"2022-01-21T23:04:05.366262Z","shell.execute_reply":"2022-01-21T23:04:05.371380Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Let's build the model:","metadata":{}},{"cell_type":"code","source":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input #preprocess input with pre-trained weights\n\ndef transfer_model(image_shape=(64,64), data_augmentation=data_augmenter()):\n    input_shape = image_shape + (3,)\n    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n                                                   include_top=False, # <== Important!!!!\n                                                   weights='imagenet')\n    base_model.trainable = False\n    inputs = tf.keras.Input(shape=input_shape) \n    x = data_augmentation(inputs)\n    x = preprocess_input(x * 255)\n    x = base_model(x, training=False)   \n    x = tfl.GlobalAveragePooling2D()(x) \n    x = tfl.Dropout(0.2)(x)\n    outputs = tfl.Dense(len(flowers), activation='softmax')(x)\n    model = tf.keras.Model(inputs, outputs)\n\n    return model\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:04:05.373266Z","iopub.execute_input":"2022-01-21T23:04:05.373720Z","iopub.status.idle":"2022-01-21T23:04:05.390816Z","shell.execute_reply.started":"2022-01-21T23:04:05.373662Z","shell.execute_reply":"2022-01-21T23:04:05.390139Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model2 = transfer_model()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:04:05.394049Z","iopub.execute_input":"2022-01-21T23:04:05.394331Z","iopub.status.idle":"2022-01-21T23:04:07.549931Z","shell.execute_reply.started":"2022-01-21T23:04:05.394297Z","shell.execute_reply":"2022-01-21T23:04:07.549203Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Define initial epochs and base_learning rate and then compile\ninitial_epochs = 50\nbase_lr = 0.001\nmodel2.compile(optimizer=tf.optimizers.Adam(learning_rate=base_lr),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:04:07.551467Z","iopub.execute_input":"2022-01-21T23:04:07.552471Z","iopub.status.idle":"2022-01-21T23:04:07.582106Z","shell.execute_reply.started":"2022-01-21T23:04:07.552419Z","shell.execute_reply":"2022-01-21T23:04:07.581196Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"history = model2.fit(train_dataset, epochs=initial_epochs, validation_data=test_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:04:07.583513Z","iopub.execute_input":"2022-01-21T23:04:07.584384Z","iopub.status.idle":"2022-01-21T23:09:08.735995Z","shell.execute_reply.started":"2022-01-21T23:04:07.584333Z","shell.execute_reply":"2022-01-21T23:09:08.735061Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_loss_acc = pd.DataFrame(history.history)\ndf_loss= df_loss_acc[['loss','val_loss']]\ndf_loss.rename(columns={'loss':'train','val_loss':'validation'},inplace=True)\ndf_acc= df_loss_acc[['accuracy','val_accuracy']]\ndf_acc.rename(columns={'accuracy':'train','val_accuracy':'validation'},inplace=True)\ndf_loss.plot(title='Model loss',figsize=(12,8)).set(xlabel='Epoch',ylabel='Loss')\ndf_acc.plot(title='Model Accuracy',figsize=(12,8)).set(xlabel='Epoch',ylabel='Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:21:22.840735Z","iopub.execute_input":"2022-01-21T23:21:22.841436Z","iopub.status.idle":"2022-01-21T23:21:23.370161Z","shell.execute_reply.started":"2022-01-21T23:21:22.841382Z","shell.execute_reply":"2022-01-21T23:21:23.369044Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"That was an improvement compared to before! Now let's do some fine tuning.\n\n## Fine Tuning\n\nLet's fine tune the model and see if we can improve the score. To do this, I will unfreeze the last few layers of the model and allow training with a smaller learning rate. ","metadata":{}},{"cell_type":"code","source":"model2.layers # See layers, freeze at base model (Functional)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:09:08.739211Z","iopub.execute_input":"2022-01-21T23:09:08.739589Z","iopub.status.idle":"2022-01-21T23:09:08.746813Z","shell.execute_reply.started":"2022-01-21T23:09:08.739543Z","shell.execute_reply":"2022-01-21T23:09:08.746182Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"base_model = model2.layers[5]\nbase_model.trainable = True\nprint(\"Number of layers in the base model: \", len(base_model.layers))\nfine_tune_at = 120 # Start fine tuning at this layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable = False\n    \nmodel2.compile(optimizer=tf.optimizers.Adam(learning_rate=base_lr*0.1),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel2.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:09:08.747946Z","iopub.execute_input":"2022-01-21T23:09:08.748338Z","iopub.status.idle":"2022-01-21T23:09:08.800099Z","shell.execute_reply.started":"2022-01-21T23:09:08.748307Z","shell.execute_reply":"2022-01-21T23:09:08.799069Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"fine_tune_epochs = 30 # fine tune for 30 more epochs\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model2.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=test_dataset)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T23:09:08.801471Z","iopub.execute_input":"2022-01-21T23:09:08.801708Z","iopub.status.idle":"2022-01-21T23:15:20.917130Z","shell.execute_reply.started":"2022-01-21T23:09:08.801664Z","shell.execute_reply":"2022-01-21T23:15:20.916198Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Not a bad improvement! The test accuracy went from ~73% to ~82-83%.  To improve this, we could try adding other regularization techniques to the model to reduce overfitting and/or add more training data.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}